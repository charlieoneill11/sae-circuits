{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "import fancy_einsum\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import transformer_lens.utils as utils\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sparse_autoencoder import SparseAutoencoder\n",
    "\n",
    "\n",
    "\n",
    "### FUNCTION DEFINITIONS ###\n",
    "\n",
    "# Loss function is MSE (reconstruction loss) + L1 norm of the learned activations + similarity loss\n",
    "def loss_fn(decoded_activations, learned_activations, resid_streams, resid_labels, lambda_=0.01, alpha_=0.5, verbose=False):\n",
    "\n",
    "    # RECONSTRUCTION LOSS\n",
    "    recon_loss = F.mse_loss(decoded_activations, resid_streams)\n",
    "\n",
    "    # SPARSITY LOSS\n",
    "    learned_activations_flat = einops.rearrange(learned_activations, 'b s n -> (b s) n')\n",
    "    sparsity_loss = torch.mean(torch.norm(learned_activations_flat, p=1, dim=1))\n",
    "\n",
    "    # SIMILARITY LOSS\n",
    "    # Pos and neg - pos is where resid_labels == 1, neg is where resid_labels == 0\n",
    "    if alpha_ > 0:\n",
    "        learned_activations_pos = learned_activations[resid_labels == 1, :, :]\n",
    "        learned_activations_neg = learned_activations[resid_labels == 0, :, :]\n",
    "        # Currently (N, S, D) and (M, S, D) -> need to be (D, S, N) and (D, S, M)\n",
    "        learned_activations_pos = einops.rearrange(learned_activations_pos, 'n s d -> d s n')\n",
    "        learned_activations_neg = einops.rearrange(learned_activations_neg, 'n s d -> d s n')\n",
    "        pos_sim_loss = calculate_similarity_loss(learned_activations_pos, learned_activations_neg, verbose=verbose)\n",
    "    else: \n",
    "        pos_sim_loss = torch.tensor(0.0)\n",
    "\n",
    "    # combine\n",
    "    return recon_loss + (lambda_ * sparsity_loss) + (alpha_ * pos_sim_loss), recon_loss, sparsity_loss, pos_sim_loss\n",
    "\n",
    "\n",
    "def train(model, n_epochs, optimizer, train_streams, eval_streams, lambda_=0.01, alpha_=0.5, verbose=False):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        learned_activations, decoded_activations = model(train_streams)\n",
    "        loss, recon_loss, sparsity_loss, pos_sim_loss = loss_fn(decoded_activations, learned_activations, train_streams, \n",
    "                                                                train_labels, lambda_=lambda_, alpha_=alpha_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % (n_epochs // 10) == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                eval_learned_activations, eval_decoded_activations = model(eval_streams)\n",
    "                eval_loss, _, _, eval_pos_sim_loss = loss_fn(eval_decoded_activations, eval_learned_activations,\n",
    "                                                             eval_streams, eval_labels, lambda_=lambda_, alpha_=alpha_, verbose=verbose)\n",
    "                print(f\"Train loss = {loss.item():.4f}, Eval loss = {eval_loss.item():.4f}\")\n",
    "    return model\n",
    "\n",
    "def feature_string_to_head_and_layer(feature_index, head_labels):\n",
    "\n",
    "    extraction = head_labels[feature_index]\n",
    "\n",
    "    if 'mlp' in extraction.lower(): \n",
    "        layer = int(extraction.split('_')[0])\n",
    "        head = 12\n",
    "        return layer, head\n",
    "\n",
    "    # Get head and layer e.g. 'L0H1' -> (0, 1)\n",
    "    # Layer is everything after L and before H\n",
    "    layer = int(re.findall(r'L(\\d+)H', extraction)[0])\n",
    "    # Head is everything after H\n",
    "    head = int(re.findall(r'H(\\d+)', extraction)[0])\n",
    "\n",
    "    return layer, head\n",
    "\n",
    "def gen_array_template(head_labels):\n",
    "\n",
    "    # Plot the ground truth (head, layer) pairs (1 if in ground truth, 0 otherwise)\n",
    "    heads = []\n",
    "    layers = []\n",
    "    for i, l in enumerate(head_labels):\n",
    "        layer, head = feature_string_to_head_and_layer(i, head_labels)\n",
    "        heads.append(head)\n",
    "        layers.append(layer)\n",
    "\n",
    "    heads = list(set(heads))\n",
    "    layers = list(set(layers))\n",
    "\n",
    "    return np.zeros((len(layers), len(heads)))\n",
    "    \n",
    "\n",
    "def gen_softmaxed_unique_to_pos(all_indices, ground_truth_array, head_labels, normalise=False):\n",
    "    # Negative and positive indices\n",
    "    positive_indices = all_indices[:250, :]\n",
    "    negative_indices = all_indices[250:, :]\n",
    "\n",
    "    unique_to_positive_array = gen_array_template(head_labels)\n",
    "    unique_to_negative_array = gen_array_template(head_labels)\n",
    "\n",
    "    for i in range(len(head_labels)):\n",
    "        # Calculate head and layer\n",
    "        layer, head = feature_string_to_head_and_layer(i, head_labels)\n",
    "\n",
    "        positive = set(positive_indices[:, i].tolist())\n",
    "        negative = set(negative_indices[:, i].tolist())\n",
    "        total_unique = positive.union(negative)\n",
    "\n",
    "        # In positive but not negative\n",
    "        unique_to_positive = list(positive - negative)\n",
    "        # In negative but not positive\n",
    "        unique_to_negative = list(negative - positive)\n",
    "\n",
    "        if normalise:\n",
    "            # Normalise by total number of unique indices\n",
    "            unique_to_positive_array[layer, head] = len(unique_to_positive) / len(total_unique)\n",
    "            unique_to_negative_array[layer, head] = len(unique_to_negative) / len(total_unique)\n",
    "        \n",
    "        else:\n",
    "            # Set the values\n",
    "            unique_to_positive_array[layer, head] = len(unique_to_positive)\n",
    "            unique_to_negative_array[layer, head] = len(unique_to_negative)\n",
    "\n",
    "    # Plot the ROC curve in plotly\n",
    "    y_true = ground_truth_array.flatten()\n",
    "    y_pred = unique_to_positive_array.flatten()\n",
    "\n",
    "    # Normalise y_pred with softmax\n",
    "    def softmax(x): return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    y_pred = softmax(y_pred)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Calculate F1\n",
    "    f1 = 2 * (tpr * (1 - fpr)) / (tpr + (1 - fpr))\n",
    "\n",
    "    return y_true, y_pred, fpr, tpr, roc_auc, f1, thresholds\n",
    "\n",
    "def gen_co_occurrence_matrix(all_indices, n_heads, n_feat):\n",
    "    co_occurrence_matrix = np.zeros((n_heads, n_heads, n_feat, n_feat))\n",
    "\n",
    "    for e in range(all_indices.shape[0]):  # For each example\n",
    "        for h1 in range(n_heads):  # For each head\n",
    "            c1 = all_indices[e, h1]  # Code in head h1\n",
    "            for h2 in range(n_heads):  # For each other head\n",
    "                if h1 != h2:  # Skip counting co-occurrence of a head with itself\n",
    "                    c2 = all_indices[e, h2]  # Code in head h2\n",
    "                    # Increment co-occurrence count for (h1, h2)\n",
    "                    co_occurrence_matrix[h1, h2, c1, c2] += 1\n",
    "\n",
    "    return co_occurrence_matrix\n",
    "\n",
    "def normalize_co_occurrence_matrix(co_occurrence_matrix):\n",
    "    # Assuming co_occurrence_matrix is of shape (n_heads, n_heads, n_feat, n_feat)\n",
    "    n_heads, _, n_feat, _ = co_occurrence_matrix.shape\n",
    "    normalized_matrix = np.zeros_like(co_occurrence_matrix)\n",
    "\n",
    "    for h1 in range(n_heads):\n",
    "        for h2 in range(n_heads):\n",
    "            if h1 != h2:  # Skip self co-occurrences\n",
    "                total_co_occurrences = np.sum(co_occurrence_matrix[h1, h2, :, :])\n",
    "                if total_co_occurrences > 0:  # Avoid division by zero\n",
    "                    normalized_matrix[h1, h2, :, :] = co_occurrence_matrix[h1, h2, :, :] / total_co_occurrences\n",
    "\n",
    "    return normalized_matrix\n",
    "\n",
    "def unique_co_occurrences(positive_matrix, negative_matrix, normalise=True):\n",
    "    # Normalize matrices\n",
    "    if normalise:\n",
    "        positive_matrix = normalize_co_occurrence_matrix(positive_matrix)\n",
    "        negative_matrix = normalize_co_occurrence_matrix(negative_matrix)\n",
    "\n",
    "    n_heads, _, n_feat, _ = positive_matrix.shape\n",
    "    unique_co_occurrence_counts = np.zeros((n_heads, n_heads))\n",
    "    \n",
    "    for h1 in range(n_heads):\n",
    "        for h2 in range(n_heads):\n",
    "            if h1 != h2:  # Skip self co-occurrences\n",
    "                # Find co-occurrences in positive not present in negative\n",
    "                unique_positives = positive_matrix[h1, h2, :, :] > 0\n",
    "                negatives = negative_matrix[h1, h2, :, :] > 0\n",
    "                # Boolean array of unique positives\n",
    "                unique = unique_positives & ~negatives\n",
    "                if normalise:\n",
    "                    # Normalize count by total co-occurrences for this head pair in positive matrix\n",
    "                    total_co_occurrences = np.sum(positive_matrix[h1, h2, :, :] > 0) + np.sum(negative_matrix[h1, h2, :, :] > 0)\n",
    "                    if total_co_occurrences > 0:  # Avoid division by zero\n",
    "                        unique_count_normalized = np.sum(unique) / total_co_occurrences\n",
    "                    else:\n",
    "                        unique_count_normalized = 0\n",
    "                    # Set normalized unique counts for this head pair\n",
    "                    unique_co_occurrence_counts[h1, h2] = unique_count_normalized\n",
    "                else:\n",
    "                    # Count unique co-occurrences\n",
    "                    unique_co_occurrence_counts[h1, h2] = np.sum(unique)\n",
    "\n",
    "    return unique_co_occurrence_counts\n",
    "\n",
    "def pairwise_cosine_similarities(pos_examples, neg_examples, eps=1e-12):\n",
    "    \"\"\"\n",
    "    pos_examples = (D, S, N)\n",
    "    neg_examples = (D, S, M)\n",
    "\n",
    "    Calculate the average cosine similarity for vectors at the same sequence\n",
    "    position in pos_examples and neg_examples, vectorized.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape tensors for dot product computation\n",
    "    pos_examples_perm = pos_examples.permute(1, 2, 0)  # Change to shape (S, N, D) for batch processing\n",
    "    neg_examples_perm = neg_examples.permute(1, 0, 2)  # Change to shape (S, D, M) for correct dot product\n",
    "\n",
    "    # Compute dot products. Now, using einsum for clarity and correctness\n",
    "    dot_products = torch.einsum('snd,sdm->snm', pos_examples_perm, neg_examples_perm)\n",
    "\n",
    "    # Calculate magnitudes for normalization\n",
    "    magnitude_p = torch.sqrt(torch.einsum('snd,snd->sn', pos_examples_perm, pos_examples_perm) + eps).unsqueeze(-1)\n",
    "    magnitude_n = torch.sqrt(torch.einsum('sdm,sdm->sm', neg_examples_perm, neg_examples_perm) + eps).unsqueeze(-2)\n",
    "\n",
    "    # Calculate cosine similarities\n",
    "    cosine_similarities = dot_products / (magnitude_p * magnitude_n + eps)\n",
    "\n",
    "    # Average the cosine similarities for each position across all N, M pairs\n",
    "    average_cosine_similarities_per_position = torch.mean(cosine_similarities, dim=(1, 2))\n",
    "\n",
    "    # Finally, average these across all sequence positions\n",
    "    final_scalar = torch.mean(average_cosine_similarities_per_position)\n",
    "\n",
    "    return final_scalar\n",
    "\n",
    "def calculate_similarity_loss(pos_examples, neg_examples, eps=1e-12, delta=1.0, verbose=False):\n",
    "\n",
    "    # Positive-negative\n",
    "    pos_neg_scalar = pairwise_cosine_similarities(pos_examples, neg_examples, eps)\n",
    "    if verbose: print(f\"Pos-neg loss = {pos_neg_scalar.item():.4f}\")\n",
    "\n",
    "    # Positive-positive\n",
    "    pos_pos_scalar = pairwise_cosine_similarities(pos_examples, pos_examples, eps)\n",
    "    if verbose: print(f\"Pos-pos loss = {pos_pos_scalar.item():.4f}\")\n",
    "    \n",
    "    return pos_neg_scalar + (delta - (pos_pos_scalar))\n",
    "\n",
    "def calculate_f1_score(y_true, y_pred):\n",
    "    # Calculate True Positives (TP)\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    # Calculate False Positives (FP)\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    # Calculate False Negatives (FN)\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    # Calculate Treu Negatives (TN)\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    \n",
    "    # Calculate Precision and Recall\n",
    "    Precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    Recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # Calculate F1 Score\n",
    "    F1 = 2 * (Precision * Recall) / (Precision + Recall) if (Precision + Recall) > 0 else 0\n",
    "    \n",
    "    return F1, Precision, Recall, TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: node\n",
      "Task: Tracr-SortFreq\n",
      "Using device: cpu\n",
      "Residual streams shape: torch.Size([500, 15, 44])\n",
      "Head labels: ['attn_k_0', 'attn_q_0', 'attn_v_0', 'attn_k_1', 'attn_q_1', 'attn_v_1', 'attn_k_2', 'attn_q_2', 'attn_v_2', 'attn_k_3', 'attn_q_3', 'attn_v_3', 'attn_k_4', 'attn_q_4', 'attn_v_4']\n",
      "Ground truth: ['attn_q_0', 'attn_k_0', 'attn_v_0', 'attn_q_3', 'attn_k_3', 'attn_v_3', 'attn_q_4', 'attn_k_4', 'attn_v_4']\n",
      "Train loss = 252.2535, Eval loss = 151.6910\n",
      "Train loss = 1.5771, Eval loss = 3.4758\n",
      "Train loss = 0.9016, Eval loss = 2.7307\n",
      "Train loss = 0.7199, Eval loss = 2.5574\n",
      "Train loss = 0.6502, Eval loss = 2.4920\n",
      "Train loss = 0.6115, Eval loss = 2.4623\n",
      "Train loss = 0.5831, Eval loss = 2.4172\n",
      "Train loss = 0.5715, Eval loss = 2.4255\n",
      "Train loss = 0.5636, Eval loss = 2.4474\n",
      "Train loss = 0.5603, Eval loss = 2.5096\n"
     ]
    }
   ],
   "source": [
    "### MAIN CODE ###\n",
    "\n",
    "task = 'tracr-sortfreq'\n",
    "task_type = 'node'\n",
    "assert task_type in ['node', 'edge'], \"Type must be either 'node' or 'edge'\"\n",
    "print(f\"Type: {task_type}\")\n",
    "task_mappings = {\n",
    "    'gt': 'Greater-than',\n",
    "    'ioi': 'Indirect Object Identification',\n",
    "    'ds': 'Docstring',\n",
    "    'induction': 'Induction',\n",
    "    'tracr-reverse': 'Tracr-Reverse',\n",
    "    'tracr-fracprev': 'Tracr-Fracprev',\n",
    "    'tracr-sort': 'Tracr-Sort',\n",
    "    'tracr-sortfreq': 'Tracr-SortFreq'\n",
    "}\n",
    "\n",
    "print(f\"Task: {task_mappings[task]}\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "num_unique = 300\n",
    "n_epochs = 10000\n",
    "num_trials = 5\n",
    "\n",
    "roc_results = []\n",
    "\n",
    "\n",
    "# Load residual streams\n",
    "resid_streams = torch.load(f\"../data/{task}/resid_heads_mean.pt\").to(device)\n",
    "head_labels = torch.load(f'../data/{task}/labels_heads_mean.pt')\n",
    "ground_truth = torch.load(f'../data/{task}/ground_truth.pt')\n",
    "print(f\"Residual streams shape: {resid_streams.shape}\")\n",
    "print(f\"Head labels: {head_labels}\")\n",
    "print(f\"Ground truth: {ground_truth}\")\n",
    "\n",
    "\n",
    "# Shuffle and create the labels\n",
    "labels = torch.ones(resid_streams.shape[0]//2) # BIG ASSUMPTION: assumes first half is positive and second half is negative\n",
    "labels = torch.cat((labels, torch.zeros_like(labels)))\n",
    "permutation = torch.randperm(resid_streams.shape[0])\n",
    "resid_shuffled = resid_streams[permutation, :, :]\n",
    "labels_shuffled = labels[permutation]\n",
    "cutoff = int(resid_shuffled.shape[1] * 0.8)\n",
    "train_streams = resid_shuffled[:cutoff, :, :].to(device)\n",
    "train_labels = labels_shuffled[:cutoff].to(device)\n",
    "eval_streams = resid_shuffled[cutoff:, :, :].to(device)\n",
    "eval_labels = labels_shuffled[cutoff:].to(device)\n",
    "\n",
    "\n",
    "model = SparseAutoencoder(n_input_features=resid_streams.shape[-1], n_learned_features=num_unique, geometric_median_dataset=None).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model = train(model, n_epochs, optimizer, train_streams, eval_streams, lambda_=0.01, alpha_=0.0)\n",
    "model = model.to('cpu')\n",
    "resid_streams = resid_streams.to('cpu')\n",
    "# Save model\n",
    "torch.save(model, f'../models/{task}/sparse_autoencoder_{task_type}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "learned_activations = model(resid_streams)[0].detach().cpu().numpy()\n",
    "all_indices = np.argmax(learned_activations, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[161, 161, 255, ..., 164, 228, 131],\n",
       "       [ 97,   6,   5, ...,  62, 259, 284],\n",
       "       [117,  42,   5, ..., 195,   5, 195],\n",
       "       ...,\n",
       "       [228, 149, 241, ..., 243, 218, 195],\n",
       "       [183, 228,  64, ..., 280, 228,  97],\n",
       "       [ 84, 225, 107, ..., 164,  75, 107]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_indices = all_indices[:250, :]\n",
    "negative_indices = all_indices[250:, :]\n",
    "positive_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[228, 228, 228, ..., 228, 228, 228],\n",
       "       [228, 228, 228, ..., 228, 228, 228],\n",
       "       [228, 228, 228, ..., 228, 228, 228],\n",
       "       ...,\n",
       "       [228, 228, 228, ..., 228, 228, 228],\n",
       "       [228, 228, 228, ..., 228, 228, 228],\n",
       "       [228, 228, 228, ..., 228, 228, 228]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_softmaxed_unique_to_pos(all_indices, ground_truth_labels, head_labels, normalise=False):\n",
    "    # Negative and positive indices\n",
    "    positive_indices = all_indices[:250, :]\n",
    "    negative_indices = all_indices[250:, :]\n",
    "\n",
    "    unique_to_positive_array = np.zeros(len(head_labels))\n",
    "    unique_to_negative_array = np.zeros(len(head_labels))\n",
    "\n",
    "    for i in range(len(head_labels)):\n",
    "\n",
    "        positive = set(positive_indices[:, i].tolist())\n",
    "        negative = set(negative_indices[:, i].tolist())\n",
    "        total_unique = positive.union(negative)\n",
    "\n",
    "        # In positive but not negative\n",
    "        unique_to_positive = list(positive - negative)\n",
    "        # In negative but not positive\n",
    "        unique_to_negative = list(negative - positive)\n",
    "\n",
    "        if normalise:\n",
    "            # Normalise by total number of unique indices\n",
    "            unique_to_positive_array[i] = len(unique_to_positive) / len(total_unique)\n",
    "            unique_to_negative_array[i] = len(unique_to_negative) / len(total_unique)\n",
    "        \n",
    "        else:\n",
    "            # Set the values\n",
    "            unique_to_positive_array[i] = len(unique_to_positive)\n",
    "            unique_to_negative_array[i] = len(unique_to_negative)\n",
    "\n",
    "    # Plot the ROC curve in plotly\n",
    "    y_true = [1 if head_labels[i] in ground_truth_labels else 0 for i in range(len(head_labels))]\n",
    "    y_pred = unique_to_positive_array.flatten()\n",
    "\n",
    "    # Normalise y_pred with softmax\n",
    "    def softmax(x): return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    y_pred = softmax(y_pred)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Calculate F1\n",
    "    f1 = 2 * (tpr * (1 - fpr)) / (tpr + (1 - fpr))\n",
    "\n",
    "    return y_true, y_pred, fpr, tpr, roc_auc, f1, thresholds\n",
    "\n",
    "y_true, y_pred, fpr, tpr, roc_auc, f1, thresholds = gen_softmaxed_unique_to_pos(all_indices, ground_truth, head_labels, normalise=True)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attn_k_0',\n",
       " 'attn_q_0',\n",
       " 'attn_v_0',\n",
       " 'attn_k_1',\n",
       " 'attn_q_1',\n",
       " 'attn_v_1',\n",
       " 'attn_k_2',\n",
       " 'attn_q_2',\n",
       " 'attn_v_2',\n",
       " 'attn_k_3',\n",
       " 'attn_q_3',\n",
       " 'attn_v_3',\n",
       " 'attn_k_4',\n",
       " 'attn_q_4',\n",
       " 'attn_v_4']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K.0',\n",
       " 'Q.0',\n",
       " 'V.0',\n",
       " 'K.1',\n",
       " 'Q.1',\n",
       " 'V.1',\n",
       " 'K.2',\n",
       " 'Q.2',\n",
       " 'V.2',\n",
       " 'K.3',\n",
       " 'Q.3',\n",
       " 'V.3',\n",
       " 'K.4',\n",
       " 'Q.4',\n",
       " 'V.4']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def head_label_formatter(head_labels):\n",
    "    formatted_labels = []\n",
    "    for label in head_labels:\n",
    "        _, matrix, layer = label.split('_')\n",
    "        formatted_labels.append(f\"{matrix.upper()}.{layer}\")\n",
    "    return formatted_labels\n",
    "\n",
    "head_label_formatter(head_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "lightblue"
          ],
          [
           1,
           "darkblue"
          ]
         ],
         "showscale": false,
         "text": [
          [
           "1",
           "1",
           "1",
           "0",
           "0",
           "0",
           "0",
           "0",
           "0",
           "1",
           "1",
           "1",
           "1",
           "1",
           "1"
          ]
         ],
         "textfont": {
          "color": "white",
          "family": "Palatino",
          "size": 16
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           1,
           1,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           1,
           1,
           1,
           1,
           1
          ]
         ]
        },
        {
         "colorscale": [
          [
           0,
           "lightblue"
          ],
          [
           1,
           "darkblue"
          ]
         ],
         "showscale": false,
         "text": [
          [
           "0.09",
           "0.09",
           "0.09",
           "0.04",
           "0.04",
           "0.03",
           "0.04",
           "0.04",
           "0.03",
           "0.06",
           "0.09",
           "0.09",
           "0.09",
           "0.09",
           "0.09"
          ]
         ],
         "textfont": {
          "color": "white",
          "family": "Palatino",
          "size": 16
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "xaxis": "x2",
         "yaxis": "y2",
         "z": [
          [
           0.0906424670058886,
           0.09068244163236584,
           0.0905199151002761,
           0.038090243307224936,
           0.038597869645599886,
           0.03375972462967869,
           0.03757772182470586,
           0.037276668147212845,
           0.03375972462967869,
           0.05566037608993027,
           0.09077636440142847,
           0.09070755098888059,
           0.09058435354930901,
           0.09066943590393602,
           0.09069514314388404
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 24
          },
          "showarrow": false,
          "text": "Ground Truth",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 24
          },
          "showarrow": false,
          "text": "Predicted",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.25,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "font": {
         "family": "Palatino",
         "size": 18
        },
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Tracr-SortFreq"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "ticktext": [
          "K.0",
          "Q.0",
          "V.0",
          "K.1",
          "Q.1",
          "V.1",
          "K.2",
          "Q.2",
          "V.2",
          "K.3",
          "Q.3",
          "V.3",
          "K.4",
          "Q.4",
          "V.4"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "title": {
          "text": "Head"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ],
         "ticktext": [
          "K.0",
          "Q.0",
          "V.0",
          "K.1",
          "Q.1",
          "V.1",
          "K.2",
          "Q.2",
          "V.2",
          "K.3",
          "Q.3",
          "V.3",
          "K.4",
          "Q.4",
          "V.4"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "title": {
          "text": "Head"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.75,
          1
         ],
         "visible": false
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.25
         ],
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Ground Truth\", \"Predicted\"), vertical_spacing=0.50)\n",
    "\n",
    "# Define the color scale\n",
    "color_scale = [[0, 'lightblue'], [1, 'darkblue']]\n",
    "formatted_labels = head_label_formatter(head_labels)\n",
    "\n",
    "# Add the ground truth subplot\n",
    "fig.add_trace(go.Heatmap(\n",
    "    z=np.array([y_true]),\n",
    "    colorscale=color_scale,\n",
    "    showscale=False,\n",
    "    text=np.array([y_true]).astype(int).astype(str),\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont=dict(size=16, color='white', family='Palatino')\n",
    "), row=1, col=1)\n",
    "\n",
    "# Add the predicted subplot\n",
    "fig.add_trace(go.Heatmap(\n",
    "    z=np.array([y_pred]),\n",
    "    colorscale=color_scale,\n",
    "    showscale=False,\n",
    "    text=np.array([y_pred]).astype(float).round(2).astype(str),\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont=dict(size=16, color='white', family='Palatino')\n",
    "), row=2, col=1)\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title=f\"{task_mappings[task]}\",\n",
    "    xaxis=dict(\n",
    "        title='Head',\n",
    "        ticktext=formatted_labels,\n",
    "        tickvals=list(range(len(head_labels))),\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        title='Head',\n",
    "        ticktext=formatted_labels,\n",
    "        tickvals=list(range(len(head_labels))),\n",
    "    ),\n",
    "    yaxis=dict(visible=False),\n",
    "    yaxis2=dict(visible=False),\n",
    "    height=400,\n",
    "    width=800,\n",
    "    template='plotly_white',\n",
    "    font=dict(size=18, family='Palatino')\n",
    ")\n",
    "\n",
    "# Make subplot titles bigger\n",
    "fig.update_annotations(font=dict(size=24))\n",
    "\n",
    "# Save figure\n",
    "fig.write_image(f\"../output/figures/pred_vs_ground_truth_{task}.pdf\")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tracr-sort'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
